{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a15bb5a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.path.dirname(os.getcwd())) # Include ../SSD in path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a16d28",
   "metadata": {},
   "source": [
    "# Introduction to SSD\n",
    "\n",
    "This code is much more complex than your prior assignment, and we recommend you to spend some time getting familiar with the code structure.\n",
    "The \"complex\" code structure is made to simplify aspects of deep learning experimentation, and help you structure the usual \"sphagetti\" deep learning code.\n",
    "\n",
    "\n",
    "All scripts in this code requires a configuration file. To **start training**, you can type:\n",
    "```\n",
    "python train.py configs/ssd300.py\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b01ea8e3",
   "metadata": {},
   "source": [
    "## Configuration files\n",
    "The key difference from previous starter codes is the use of configuration files. This enables us to change small parts of the experiment without changing hard-coded values (e.g. learning rate in previous assignments).\n",
    "\n",
    "If you take a look in [`configs/ssd300.py`](../configs/ssd300.py) you will notice a large set of objects describing model architecture (`backbone` and `model`), the optimizer, dataset, data loading, and hyperparameters.\n",
    "\n",
    "To load the config we can write the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66214f45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving SSD outputs to: outputs/\n"
     ]
    }
   ],
   "source": [
    "from ssd.utils import load_config\n",
    "cfg = load_config(\"../configs/ssd300.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "879a680c",
   "metadata": {},
   "source": [
    "`cfg` supports access syntax, where all objects in `configs/ssd300.py` are accessible via their attribute name.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ddc89b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'feature_extractor': '${backbone}', 'anchors': '${anchors}', 'loss_objective': '${loss_objective}', 'num_classes': 11, '_target_': <class 'ssd.modeling.ssd.SSD300'>}\n"
     ]
    }
   ],
   "source": [
    "print(cfg.model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7b97d7",
   "metadata": {},
   "source": [
    "If we print `cfg.model`, notice that it returns a dictionary and not the model object itself (which is `SSD300` from [`ssd/modeling/ssd.py`](../ssd/modeling/ssd.py)). This is because the model is defined \"lazily\" (wrapped with a `LazyCall`).\n",
    "\n",
    "To create the model, we have to instantiate it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8daf7c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SSD300(\n",
      "  (feature_extractor): BasicModel()\n",
      "  (loss_func): SSDMultiboxLoss(\n",
      "    (sl1_loss): SmoothL1Loss()\n",
      "  )\n",
      "  (regression_heads): ModuleList(\n",
      "    (0): Conv2d(128, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): Conv2d(256, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (2-3): 2 x Conv2d(128, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4-5): 2 x Conv2d(64, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (classification_heads): ModuleList(\n",
      "    (0): Conv2d(128, 44, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): Conv2d(256, 66, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (2-3): 2 x Conv2d(128, 66, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4-5): 2 x Conv2d(64, 44, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from tops.config import instantiate\n",
    "model = instantiate(cfg.model)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67edd3a",
   "metadata": {},
   "source": [
    "Another example, we can load the first batch of the dataset and run a forward pass with the model:\n",
    "\n",
    "(Task4a needs to be implemented in order for this to run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af819ae7",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileExistsError",
     "evalue": "[Errno 17] File exists: 'data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m/usr/lib/python3.10/pathlib.py:1175\u001b[0m, in \u001b[0;36mPath.mkdir\u001b[0;34m(self, mode, parents, exist_ok)\u001b[0m\n\u001b[1;32m   1174\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1175\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_accessor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmkdir\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1176\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/original_mnist'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m dataloader_train \u001b[38;5;241m=\u001b[39m \u001b[43minstantiate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataloader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mtype\u001b[39m(dataloader_train))\n\u001b[1;32m      3\u001b[0m batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(dataloader_train))\n",
      "File \u001b[0;32m~/TDT4265/assignment4/SSD/tops/config/instantiate.py:60\u001b[0m, in \u001b[0;36minstantiate\u001b[0;34m(cfg, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [instantiate(x, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m cfg]\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(cfg, abc\u001b[38;5;241m.\u001b[39mMapping) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_target_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m cfg:\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;66;03m# conceptually equivalent to hydra.utils.instantiate(cfg) with _convert_=all,\u001b[39;00m\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;66;03m# but faster: https://github.com/facebookresearch/hydra/issues/1200\u001b[39;00m\n\u001b[0;32m---> 60\u001b[0m     cfg \u001b[38;5;241m=\u001b[39m {k: instantiate(v) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m cfg\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m cfg\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_target_\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m instantiate(\u001b[38;5;28mcls\u001b[39m)\n",
      "File \u001b[0;32m~/TDT4265/assignment4/SSD/tops/config/instantiate.py:60\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [instantiate(x, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m cfg]\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(cfg, abc\u001b[38;5;241m.\u001b[39mMapping) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_target_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m cfg:\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;66;03m# conceptually equivalent to hydra.utils.instantiate(cfg) with _convert_=all,\u001b[39;00m\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;66;03m# but faster: https://github.com/facebookresearch/hydra/issues/1200\u001b[39;00m\n\u001b[0;32m---> 60\u001b[0m     cfg \u001b[38;5;241m=\u001b[39m {k: \u001b[43minstantiate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m cfg\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m cfg\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_target_\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m instantiate(\u001b[38;5;28mcls\u001b[39m)\n",
      "File \u001b[0;32m~/TDT4265/assignment4/SSD/tops/config/instantiate.py:76\u001b[0m, in \u001b[0;36minstantiate\u001b[0;34m(cfg, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m callable(\u001b[38;5;28mcls\u001b[39m), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_target_ \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not define a callable object\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 76\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m     78\u001b[0m     logger \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mgetLogger(\u001b[38;5;18m__name__\u001b[39m)\n",
      "File \u001b[0;32m~/TDT4265/assignment4/SSD/ssd/data/mnist.py:16\u001b[0m, in \u001b[0;36mMNISTDetectionDataset.__init__\u001b[0;34m(self, data_dir, is_train, transform)\u001b[0m\n\u001b[1;32m     14\u001b[0m data_dir \u001b[38;5;241m=\u001b[39m pathlib\u001b[38;5;241m.\u001b[39mPath(data_dir)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;241m=\u001b[39m transform\n\u001b[0;32m---> 16\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimages, labels, boxes_ltrb \u001b[38;5;241m=\u001b[39m \u001b[43mload_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mboxes_ltrb \u001b[38;5;241m=\u001b[39m boxes_ltrb\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;241m=\u001b[39m transform\n",
      "File \u001b[0;32m~/TDT4265/assignment4/SSD/ssd/data/mnist_object_detection/mnist_object_detection.py:108\u001b[0m, in \u001b[0;36mload_dataset\u001b[0;34m(dirpath, is_train, max_digit_size, min_digit_size, imsize, max_digits_per_image)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_dataset\u001b[39m(dirpath: pathlib\u001b[38;5;241m.\u001b[39mPath,\n\u001b[1;32m    102\u001b[0m                  is_train: \u001b[38;5;28mbool\u001b[39m,\n\u001b[1;32m    103\u001b[0m                  max_digit_size: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m,\n\u001b[1;32m    104\u001b[0m                  min_digit_size: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m15\u001b[39m,\n\u001b[1;32m    105\u001b[0m                  imsize: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m\u001b[38;5;241m300\u001b[39m,\n\u001b[1;32m    106\u001b[0m                  max_digits_per_image: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m20\u001b[39m):\n\u001b[1;32m    107\u001b[0m     num_images \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10000\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_train \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m1000\u001b[39m\n\u001b[0;32m--> 108\u001b[0m     X_train, Y_train, X_test, Y_test \u001b[38;5;241m=\u001b[39m \u001b[43mmnist\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    109\u001b[0m     X, Y \u001b[38;5;241m=\u001b[39m X_train, Y_train\n\u001b[1;32m    110\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_train:\n",
      "File \u001b[0;32m~/TDT4265/assignment4/SSD/ssd/data/mnist_object_detection/mnist.py:51\u001b[0m, in \u001b[0;36mload\u001b[0;34m()\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m():\n\u001b[0;32m---> 51\u001b[0m     \u001b[43mdownload_mnist\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m     extract_mnist()\n\u001b[1;32m     53\u001b[0m     dataset_path \u001b[38;5;241m=\u001b[39m SAVE_PATH\u001b[38;5;241m.\u001b[39mjoinpath(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmnist.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/TDT4265/assignment4/SSD/ssd/data/mnist_object_detection/mnist.py:18\u001b[0m, in \u001b[0;36mdownload_mnist\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdownload_mnist\u001b[39m():\n\u001b[0;32m---> 18\u001b[0m     \u001b[43mSAVE_PATH\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmkdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexist_ok\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparents\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m     base_url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttp://yann.lecun.com/exdb/mnist/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m filename:\n",
      "File \u001b[0;32m/usr/lib/python3.10/pathlib.py:1179\u001b[0m, in \u001b[0;36mPath.mkdir\u001b[0;34m(self, mode, parents, exist_ok)\u001b[0m\n\u001b[1;32m   1177\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m parents \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparent \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m   1178\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m-> 1179\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmkdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparents\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexist_ok\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   1180\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmkdir(mode, parents\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, exist_ok\u001b[38;5;241m=\u001b[39mexist_ok)\n\u001b[1;32m   1181\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[1;32m   1182\u001b[0m     \u001b[38;5;66;03m# Cannot rely on checking for EEXIST, since the operating system\u001b[39;00m\n\u001b[1;32m   1183\u001b[0m     \u001b[38;5;66;03m# could give priority to other errors like EACCES or EROFS\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.10/pathlib.py:1175\u001b[0m, in \u001b[0;36mPath.mkdir\u001b[0;34m(self, mode, parents, exist_ok)\u001b[0m\n\u001b[1;32m   1171\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1172\u001b[0m \u001b[38;5;124;03mCreate a new directory at this given path.\u001b[39;00m\n\u001b[1;32m   1173\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1174\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1175\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_accessor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmkdir\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1176\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m:\n\u001b[1;32m   1177\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m parents \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparent \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m:\n",
      "\u001b[0;31mFileExistsError\u001b[0m: [Errno 17] File exists: 'data'"
     ]
    }
   ],
   "source": [
    "dataloader_train = instantiate(cfg.data_train.dataloader)\n",
    "print(type(dataloader_train))\n",
    "batch = next(iter(dataloader_train))\n",
    "for key, item in batch.items():\n",
    "    print(key, \"has the shape:\", item.shape)\n",
    "gpu_transform = instantiate(cfg.data_train.gpu_transform)\n",
    "batch = gpu_transform(batch)\n",
    "bbox_delta, confidences = model(batch[\"image\"])\n",
    "print(f\"The model predicted anchors with  bbox delta: {bbox_delta.shape} and confidences: {confidences.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f15dce",
   "metadata": {},
   "source": [
    "You might ask yourself, why? At first sight, this seems very complicated rather than plain-old  hard coded values.\n",
    "\n",
    "The reason is easy manipulation of experiments. If I want to run the same experiment, but with a different batch size, I can change it with the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b474c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets print the batch size of the original data loader:\n",
    "print(\"Original batch size:\", dataloader_train.batch_size)\n",
    "cfg.train.batch_size = 2 # Setting the batch size to 2\n",
    "dataloader_train = instantiate(cfg.data_train.dataloader)\n",
    "print(\"New batch size:\", dataloader_train.batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c120d29c",
   "metadata": {},
   "source": [
    "Another reason is **configuration inheritance**.  This allows us to change cirtain aspects of the config without defining the config from scratch.\n",
    "\n",
    "Take a look in [`configs/change_lr.py`](../configs/change_lr.py) and notice that we inherit from the original config file.\n",
    "The only changes done are to the lr."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655e002d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = load_config(\"../configs/change_lr.py\")\n",
    "model = instantiate(cfg.model)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fcf5864",
   "metadata": {},
   "source": [
    "# Useful commands:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3397a7a7",
   "metadata": {},
   "source": [
    "#### Training and evaluation\n",
    "To start training:\n",
    "```\n",
    "python train.py  configs/ssd300.py\n",
    "```\n",
    "\n",
    "To only run evaluation:\n",
    "```\n",
    "python train.py  configs/ssd300.py --evaluate-only\n",
    "```\n",
    "\n",
    "#### Demo.py\n",
    "\n",
    "For MNIST:\n",
    "```\n",
    "python demo.py configs/ssd300.py demo/mnist demo/mnist_output\n",
    "```\n",
    "\n",
    "\n",
    "#### Runtime analysis:\n",
    "```\n",
    "python3 runtime_analysis.py configs/ssd300.py\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
